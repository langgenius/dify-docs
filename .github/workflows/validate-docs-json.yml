name: Validate docs.json

on:
  pull_request:
    branches: [main, revamp]
    paths:
      - 'docs.json'

permissions:
  contents: read
  pull-requests: write

jobs:
  validate-structure:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Create validation script
        run: |
          cat > /tmp/validate_docs_json.py << 'EOFPYTHON'
          import json
          import sys
          from pathlib import Path
          from typing import Set, List, Dict, Any

          class DocsJsonValidator:
              def __init__(self, repo_root: Path):
                  self.repo_root = repo_root
                  self.docs_json_path = repo_root / "docs.json"
                  self.errors = []
                  self.warnings = []
                  
                  with open("tools/translate/config.json", "r") as f:
                      config = json.load(f)
                      self.source_lang = config.get("source_language", "en")
                      self.target_langs = config.get("target_languages", ["zh", "ja"])
                      self.all_langs = [self.source_lang] + self.target_langs
                      
                      self.lang_dirs = {}
                      for lang_code in self.all_langs:
                          if lang_code in config.get("languages", {}):
                              self.lang_dirs[lang_code] = config["languages"][lang_code]["directory"]
                          else:
                              self.lang_dirs[lang_code] = lang_code

              def load_docs_json(self) -> Dict:
                  try:
                      with open(self.docs_json_path, 'r', encoding='utf-8') as f:
                          return json.load(f)
                  except json.JSONDecodeError as e:
                      self.errors.append(f"Invalid JSON syntax in docs.json: {e}")
                      return {}
                  except FileNotFoundError:
                      self.errors.append("docs.json file not found")
                      return {}

              def validate_json_schema(self, docs_data: Dict) -> bool:
                  required_fields = ['name', 'navigation']
                  for field in required_fields:
                      if field not in docs_data:
                          self.errors.append(f"Missing required field: {field}")
                          return False
                  return True

              def extract_file_paths(self, pages: Any, collected: Set[str]):
                  if isinstance(pages, str):
                      collected.add(pages)
                  elif isinstance(pages, dict):
                      if 'pages' in pages:
                          self.extract_file_paths(pages['pages'], collected)
                      elif 'page' in pages:
                          collected.add(pages['page'])
                  elif isinstance(pages, list):
                      for item in pages:
                          self.extract_file_paths(item, collected)

              def get_language_section(self, docs_data: Dict, lang: str) -> Dict:
                  nav = docs_data.get('navigation', {})
                  
                  if 'versions' in nav and len(nav['versions']) > 0:
                      languages = nav['versions'][0].get('languages', [])
                  elif 'languages' in nav:
                      languages = nav['languages']
                  else:
                      return {}
                  
                  for lang_data in languages:
                      if lang_data.get('language') == lang:
                          return lang_data
                  return {}

              def validate_file_existence(self, docs_data: Dict):
                  for lang in self.all_langs:
                      lang_section = self.get_language_section(docs_data, lang)
                      if not lang_section:
                          continue
                      
                      file_paths = set()
                      if 'dropdowns' in lang_section:
                          for dropdown in lang_section['dropdowns']:
                              if 'pages' in dropdown:
                                  self.extract_file_paths(dropdown['pages'], file_paths)
                      
                      for file_path in file_paths:
                          mdx_path = self.repo_root / f"{file_path}.mdx"
                          md_path = self.repo_root / f"{file_path}.md"
                          
                          if not mdx_path.exists() and not md_path.exists():
                              self.errors.append(f"Referenced file not found: {file_path} (.md or .mdx)")

              def validate_language_consistency(self, docs_data: Dict):
                  sections = {}
                  for lang in self.all_langs:
                      lang_section = self.get_language_section(docs_data, lang)
                      if lang_section:
                          sections[lang] = lang_section
                  
                  if len(sections) < len(self.all_langs):
                      missing = set(self.all_langs) - set(sections.keys())
                      self.warnings.append(f"Missing language sections: {', '.join(missing)}")
                  
                  if len(sections) < 2:
                      return
                  
                  source_section = sections.get(self.source_lang)
                  if not source_section:
                      return
                  
                  source_dropdowns = source_section.get('dropdowns', [])
                  source_dropdown_count = len(source_dropdowns)
                  
                  for lang in self.target_langs:
                      if lang not in sections:
                          continue
                      
                      target_dropdowns = sections[lang].get('dropdowns', [])
                      target_dropdown_count = len(target_dropdowns)
                      
                      if source_dropdown_count != target_dropdown_count:
                          self.warnings.append(
                              f"Dropdown count mismatch between {self.source_lang} ({source_dropdown_count}) "
                              f"and {lang} ({target_dropdown_count})"
                          )

              def validate_no_duplicate_paths(self, docs_data: Dict):
                  for lang in self.all_langs:
                      lang_section = self.get_language_section(docs_data, lang)
                      if not lang_section:
                          continue
                      
                      file_paths = set()
                      duplicates = []
                      
                      def check_duplicates(pages: Any):
                          if isinstance(pages, str):
                              if pages in file_paths:
                                  duplicates.append(pages)
                              file_paths.add(pages)
                          elif isinstance(pages, dict):
                              if 'pages' in pages:
                                  check_duplicates(pages['pages'])
                              elif 'page' in pages:
                                  path = pages['page']
                                  if path in file_paths:
                                      duplicates.append(path)
                                  file_paths.add(path)
                          elif isinstance(pages, list):
                              for item in pages:
                                  check_duplicates(item)
                      
                      if 'dropdowns' in lang_section:
                          for dropdown in lang_section['dropdowns']:
                              if 'pages' in dropdown:
                                  check_duplicates(dropdown['pages'])
                      
                      if duplicates:
                          self.errors.append(f"Duplicate file paths in {lang} section: {', '.join(duplicates)}")

              def run_validation(self) -> bool:
                  docs_data = self.load_docs_json()
                  if not docs_data:
                      return False
                  
                  if not self.validate_json_schema(docs_data):
                      return False
                  
                  self.validate_file_existence(docs_data)
                  self.validate_language_consistency(docs_data)
                  self.validate_no_duplicate_paths(docs_data)
                  
                  return len(self.errors) == 0

          if __name__ == "__main__":
              repo_root = Path.cwd()
              validator = DocsJsonValidator(repo_root)
              
              success = validator.run_validation()
              
              if validator.errors:
                  print("ERRORS:")
                  for error in validator.errors:
                      print(f"  ❌ {error}")
              
              if validator.warnings:
                  print("\nWARNINGS:")
                  for warning in validator.warnings:
                      print(f"  ⚠️  {warning}")
              
              if success:
                  print("\n✅ docs.json validation passed")
                  sys.exit(0)
              else:
                  print(f"\n❌ docs.json validation failed with {len(validator.errors)} error(s)")
                  sys.exit(1)
          EOFPYTHON

      - name: Run validation
        id: validate
        run: |
          python /tmp/validate_docs_json.py 2>&1 | tee /tmp/validation_output.log
          VALIDATION_EXIT_CODE=${PIPESTATUS[0]}
          
          if [ $VALIDATION_EXIT_CODE -ne 0 ]; then
            echo "validation_failed=true" >> $GITHUB_OUTPUT
            exit 1
          else
            echo "validation_failed=false" >> $GITHUB_OUTPUT
          fi

      - name: Comment validation results on PR
        if: failure() && steps.validate.outputs.validation_failed == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let validationLog = '';
            
            try {
              validationLog = fs.readFileSync('/tmp/validation_output.log', 'utf8');
            } catch (e) {
              validationLog = 'Could not read validation log';
            }

            const comment = `## ❌ docs.json Validation Failed

            The docs.json file has structural issues that need to be fixed:

            \`\`\`
            ${validationLog}
            \`\`\`

            Please ensure:
            - All referenced files exist in the repository
            - Language sections (en/zh/ja) are consistent
            - No duplicate file paths within a language section
            - Required fields are present (name, navigation)
            - Valid JSON syntax

            Refer to the [Mintlify docs.json schema](https://mintlify.com/docs.json) for more details.`;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: comment
            });
