---
title: Models
description: Learn about the Different Models Supported by Dify.
---

<Warning>
    "Models" have been fully integrated into a "Plugin" ecosystem. For detailed development instructions on model plugins, please refer to [Plugin Development](/en/plugins/quick-start/develop-plugins/model-plugin/README). The following content has been archived.
</Warning>

Dify is a development platform for AI application based on LLM Apps, when you are using Dify for the first time, you need to go to **Settings --> Model Providers** to add and configure the LLM you are going to use.

![Settings - Model Provider](https://assets-docs.dify.ai/dify-enterprise-mintlify/en/guides/model-configuration/941524058c800a06d39290c48d14673b.png)

Dify supports major model providers like OpenAI's GPT series and Anthropic's Claude series. Each model's capabilities and parameters differ, so select a model provider that suits your application's needs. **Obtain the API key from the model provider's official website before using it in Dify.**

## Model Types in Dify

Dify classifies models into 4 types, each for different uses:

1.  **System Inference Models:** Used in applications for tasks like chat, name generation, and suggesting follow-up questions.

    > Providers include [OpenAI](https://platform.openai.com/account/api-keys)ã€[Azure OpenAI Service](https://azure.microsoft.com/en-us/products/ai-services/openai-service/)ã€[Anthropic](https://console.anthropic.com/account/keys)ã€Hugging Face Hubã€Replicateã€Xinferenceã€OpenLLMã€[iFLYTEK SPARK](https://www.xfyun.cn/solutions/xinghuoAPI)ã€[WENXINYIYAN](https://console.bce.baidu.com/qianfan/ais/console/applicationConsole/application)ã€[TONGYI](https://dashscope.console.aliyun.com/api-key\_management?spm=a2c4g.11186623.0.0.3bbc424dxZms9k)ã€[Minimax](https://api.minimax.chat/user-center/basic-information/interface-key)ã€ZHIPU(ChatGLM)ã€[Ollama](/en/development/models-integration/ollama)ã€[LocalAI](https://github.com/mudler/LocalAI)ã€[GPUStack](https://github.com/gpustack/gpustack).
2.  **Embedding Models:** Employed for embedding segmented documents in knowledge and processing user queries in applications.

    > Providers include OpenAI, ZHIPU (ChatGLM), Jina AI([Jina Embeddings](https://jina.ai/embeddings/)).
3.  [Rerank Models](/en/learn-more/extended-reading/retrieval-augment/rerank)**:** Enhance search capabilities in LLMs.

    > Providers include Cohere, Jina AI([Jina Reranker](https://jina.ai/reranker)).
4.  **Speech-to-Text Models:** Convert spoken words to text in conversational applications.

    > Provider: OpenAI.

Dify plans to add more LLM providers as technology and user needs evolve.

## Hosted Model Trial Service

Dify offers trial quotas for cloud service users to experiment with different models. Set up your model provider before the trial ends to ensure uninterrupted application use.

* OpenAI Hosted Model Trial: Includes 200 invocations for models like GPT3.5-turbo, GPT3.5-turbo-16k, text-davinci-003 models.

## Setting the Default Model

Dify automatically selects the default model based on usage. Configure this in `Settings > Model Provider`.

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/en/guides/model-configuration/c5ac5f32deb020a8aae46045d3ee9c8d.png)

## Model Integration Settings

Choose your model in Dify's `Settings > Model Provider`.

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/en/guides/model-configuration/b55cb7d0dcff7ef14cdf6e6aca207790.png)

Model providers fall into two categories:

1. Proprietary Models: Developed by providers such as OpenAI and Anthropic.
2. Hosted Models: Offer third-party models, like Hugging Face and Replicate.

Integration methods differ between these categories.

**Proprietary Model Providers:** Dify connects to all models from an integrated provider. Set the provider's API key in Dify to integrate.

<Info>
Dify uses [PKCS1\_OAEP](https://pycryptodome.readthedocs.io/en/latest/src/cipher/oaep.html) encryption to protect your API keys. Each user (tenant) has a unique key pair for encryption, ensuring your API keys remain confidential.
</Info>

**Hosted Model Providers:** Integrate third-party models individually.

Specific integration methods are not detailed here.

* [Hugging Face](/en/development/models-integration/hugging-face)
* [Replicate](/en/development/models-integration/replicate)
* [Xinference](/en/development/models-integration/xinference)
* [OpenLLM](/en/development/models-integration/openllm)

## Using Models

Once configured, these models are ready for application use.

![](https://assets-docs.dify.ai/dify-enterprise-mintlify/en/guides/model-configuration/6e74424124cfcfe224d3c083f90b54d2.png)

## Supported Providers
Dify supports the below model providers out-of-box:

<table>
  <thead>
    <tr>
      <th>Provider</th>
      <th>LLM</th>
      <th>Text Embedding</th>
      <th>Rerank</th>
      <th>Speech to text</th>
      <th>TTS</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>OpenAI</td>
      <td>âœ”ï¸(ğŸ› ï¸)(ğŸ‘“)</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
    </tr>
    <tr>
      <td>Anthropic</td>
      <td>âœ”ï¸(ğŸ› ï¸)</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Azure OpenAI</td>
      <td>âœ”ï¸(ğŸ› ï¸)(ğŸ‘“)</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
    </tr>
    <tr>
      <td>Gemini</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Google Cloud</td>
      <td>âœ”ï¸(ğŸ‘“)</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Nvidia API Catalog</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Nvidia NIM</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Nvidia Triton Inference Server</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>AWS Bedrock</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>OpenRouter</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Cohere</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>together.ai</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Ollama</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Mistral AI</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>groqcloud</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Replicate</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Hugging Face</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Xorbits inference</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
    </tr>
    <tr>
      <td>Zhipu AI</td>
      <td>âœ”ï¸(ğŸ› ï¸)(ğŸ‘“)</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Baichuan</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Spark</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Minimax</td>
      <td>âœ”ï¸(ğŸ› ï¸)</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Tongyi</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td>âœ”ï¸</td>
    </tr>
    <tr>
      <td>Wenxin</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Moonshot AI</td>
      <td>âœ”ï¸(ğŸ› ï¸)</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Tencent Cloud</td>
      <td></td>
      <td></td>
      <td></td>
      <td>âœ”ï¸</td>
      <td></td>
    </tr>
    <tr>
      <td>Stepfun</td>
      <td>âœ”ï¸(ğŸ› ï¸)(ğŸ‘“)</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>VolcanoEngine</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>01.AI</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>360 Zhinao</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Azure AI Studio</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>deepseek</td>
      <td>âœ”ï¸(ğŸ› ï¸)</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Tencent Hunyuan</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>SILICONFLOW</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Jina AI</td>
      <td></td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>ChatGLM</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Xinference</td>
      <td>âœ”ï¸(ğŸ› ï¸)(ğŸ‘“)</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>OpenLLM</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>LocalAI</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
    </tr>
    <tr>
      <td>OpenAI API-Compatible</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td>âœ”ï¸</td>
      <td></td>
    </tr>
    <tr>
      <td>PerfXCloud</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Lepton AI</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>novita.ai</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Amazon Sagemaker</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>Text Embedding Inference</td>
      <td></td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPUStack</td>
      <td>âœ”ï¸(ğŸ› ï¸)(ğŸ‘“)</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td></td>
      <td></td>
    </tr>
    <tr>
      <td>GPUStack</td>
      <td>âœ”ï¸(ğŸ”§ï¸)(ğŸ‘“)</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
      <td>âœ”ï¸</td>
    </tr>
  </tbody>
</table>

where (ğŸ› ï¸) ï¸ denotes "function calling" and (ğŸ‘“) denotes "support for vision".

{/*
Contributing Section
DO NOT edit this section!
It will be automatically generated by the script.
*/}

---

[Edit this page](https://github.com/langgenius/dify-docs/edit/main/en/documentation/pages/workspace/readme.mdx) | [Report an issue](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)

