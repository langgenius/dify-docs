```mdx
---
title: "10分钟快速入门"
description: "通过一个简单的应用程序快速进入Dify"
icon: "forward"
---

Dify的真正价值在于，无论想法多么复杂，都能轻松地构建、部署和扩展。它为快速原型设计、流畅迭代和任何级别的可靠部署而构建。

让我们开始学习如何将可靠的大型语言模型（LLM）集成到您的应用程序中。在本指南中，您将构建一个简单的聊天机器人，该机器人可以分类用户的问题，直接使用大型语言模型响应，并通过国家特定的趣味事实增强响应。

<iframe 
  className="w-full aspect-video rounded-xl" 
  src="https://www.youtube.com/embed/opKZRpfd80k?si=HEkyjRpiYheMyrZ0" 
  title="Dify Quick Start Video" 
  frameBorder="0" 
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
  allowFullScreen 
/>

## 第一步：创建一个新工作流（2分钟）

1. 前往 **Studio** > **工作流** > **从空白创建** > **编排** > **新建对话流** > **创建**

## 第二步：添加工作流节点（6分钟）

<Tip>
  当您想引用任何变量时，先输入 `{` 或 `/`，您就可以看到工作流中可用的不同变量。
</Tip>

### 1. LLM节点和输出：理解并回答问题

<Info>
  `LLM` 节点向大型语言模型发送提示词，以根据用户输入生成响应。它抽象了API调用、速率限制和基础设施的复杂性，因此您只需专注于设计逻辑。
</Info>

<Steps>
  <Step title="创建LLM节点">
    使用`添加节点`按钮创建一个LLM节点，并将其连接到您的开始节点
  </Step>
  
  <Step title="配置模型">
    选择一个默认模型
  </Step>
  
  <Step title="设置系统提示词">
    将以下内容粘贴到系统提示词字段中：

    ```text
    用户将询问有关某个国家的问题。问题是 {{sys.query}}  
    任务： 
    1. 确定提到的国家。 
    2. 明确地重新表述问题。 
    3. 使用一般知识回答问题。 
    
    以以下JSON格式响应： 
    {   
      "country": "<country name>",
      "question": "<rephrased question>",
      "answer": "<direct answer to the question>" 
    }
    ```
  </Step>
  
  <Step title="启用结构化输出">
    **启用结构化输出** 允许您轻松控制LLM的返回内容，并确保下游使用时的输出一致且可机器读取，以进行精确的数据提取或条件逻辑。
    
    - 切换输出变量结构化开关为ON > `配置`，然后点击`从JSON导入`
    - 粘贴：
    
    ```json
    {   
      "country": "string",   
      "question": "string",   
      "answer": "string" 
    }
    ```
  </Step>
</Steps>

### 2. 代码块：获取趣味事实

<Info>
  `代码`节点使用代码执行自定义逻辑。它允许您在可视化工作流中恰当插入代码，避免搭建整个后端。
</Info>

<Steps>
  <Step title="创建代码节点">
    使用`添加节点`按钮创建一个`代码`节点，并连接到LLM块
  </Step>
  
  <Step title="配置输入变量">
    将一个`输入变量`名称更改为“country”，并将变量设置为`structured_output` > `country`
  </Step>
  
  <Step title="添加Python代码">
    将以下代码粘贴到`PYTHON3`中：

    ```python
    def main(country: str) -> dict:     
      country_name = country.lower()     
      fun_facts = {
        "japan": "日本有超过500万台自动售货机。",
        "france": "法国是世界上访问量最大的国家。",
        "italy": "意大利拥有的联合国教科文组织世界遗产地比任何其他国家都多。"     
      }     
      fun_fact = fun_facts.get(country_name, f"No fun fact available for {country.title()}.")
      return {"fun_fact": fun_fact}
    ```
  </Step>
  
  <Step title="重命名输出变量">
    将输出变量`result`更改为`fun_fact`，使变量标签更清晰
  </Step>
</Steps>

### 3. 答案节点：最终答复用户

<Info>
  `答案`节点创建一个干净的最终输出以返回。
</Info>

<Steps>
  <Step title="创建答案节点">
    使用`添加节点`按钮创建一个`答案`节点
  </Step>
  
  <Step title="配置答案字段">
    将以下内容粘贴到答案字段中：

    ```text
    Q: {{ structured_output.question }} 

    A: {{ structured_output.answer }} 

    趣味事实: {{ fun_fact }}
    ```
  </Step>
</Steps>

结束工作流：

<img
  src="/images/quick-start-workflow-overview.png"
  alt="完整的工作流图，显示连接的LLM、代码和答案节点"
  style={{ width: "100%" }}
/>

---

## 第三步：测试机器人（3分钟）

点击`预览`，然后询问：

- "法国的首都是什么？"
- "告诉我关于日本美食的信息"
- "描述意大利的文化"
- 任何其他问题

确保您的机器人按预期工作！

## 您已完成机器人！

本指南展示了如何在不重新构建基础设施的情况下可靠且可扩展地集成大型语言模型。借助Dify的可视化工作流和模块化节点，您不仅能更快地构建，还能采用干净、可投入生产的架构来构建由大型语言模型驱动的应用程序。
```

{/*
Contributing Section
DO NOT edit this section!
It will be automatically generated by the script.
*/}

---

[编辑此页面](https://github.com/langgenius/dify-docs/edit/main/zh-hans/documzh-hanstation/pages/getting-started/quick-start.mdx) | [提交问题](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)

