---
title: 运行时
icon: "cube"
---

<Note> ⚠️ 本文档由 AI 自动翻译。如有任何不准确之处，请参考[英文原版](/en/use-dify/build/runtime)。</Note>

运行时是工作流运行的执行环境，它设定了 LLM 可以访问和执行的边界。

Dify 提供两种运行时环境：**沙盒运行时**和**经典运行时**，各自针对不同的使用场景进行了优化。

## 概览

<Tabs>
    <Tab title="沙盒运行时">
    <Check>
        **适用场景：** 需要 LLM 自主解决问题的复杂任务。功能更强大，但速度更慢、Token 消耗更高。
    </Check>

    沙盒运行时使 LLM 能够在隔离环境中**执行命令**。你能在终端中用命令完成的任何操作，它们都能做到：

    - **运行脚本和程序** - 执行代码来处理数据、生成输出或执行任意计算

    - **按需安装所需工具** - 使用 pip 或其他包管理器按需下载库和工具

    - **访问外部资源** - 从 URL 获取文件、克隆仓库或从外部来源检索数据

    - **处理文件** - 访问[文件系统](/zh/use-dify/build/file-system)中的资源（如[技能（Skill）](/zh/use-dify/build/file-system#技能skill)），跨格式处理文件，并使用脚本和已安装工具生成多模态产物

    <Tip>
        在沙盒运行时中，Agent 节点同时承担了 LLM 和 Agent 的角色。

        对于不需要这些高级功能的简单快速任务，可以关闭 **[Agent 模式](/zh/use-dify/nodes/agent#启用命令执行agent-模式)** 来获得更快的响应和更低的 Token 成本。
    </Tip>

    **LLM 成为真正的 Agent**。只要模型具有强大的工具调用和推理能力，它就能自主决定运行什么命令并执行它们来完成任务。

    LLM 的能力越强，就越需要在沙盒中运行。隔离环境在赋予它们足够自由度的同时，确保了安全运行。

    <Info>
        默认沙盒提供商：

        - Dify Cloud 使用 E2B。

        - 自托管部署使用 SSH VM。

        在**设置** > **沙盒提供商**中选择和配置其他提供商。
    </Info>

    </Tab>
    <Tab title="经典运行时">

    <Check>
        **适用场景：** 简单快速的任务。功能较少，但速度更快、效率更高。
    </Check>

    在经典运行时中，LLM 做它们最擅长的事：分析信息、生成文本、推理问题，并智能地使用预配置的工具来完成任务。

    可以把它想象成给某人一套特定的工具包——他们很有能力，但**仅限于你提供的工具范围**。

    </Tab>
</Tabs>

## 快速对比

| 维度                     | 沙盒运行时                    | 经典运行时                     |
|:------------------------------|:-------------------------------------|:------------------------------------|
| **适用场景**                  | 复杂的自主问题解决  | 简单、明确的任务          |
| **LLM 自主性**              | 运行所需的任何命令            | 使用你配置的工具            |
| **文件系统**               | ✅                                    | ❌                                  |
| **技能（Skill）**                    | ✅                                    | ❌                                  |
| **应用导出格式**         | `.zip`（DSL + 资源文件）        | `.yml`（DSL 文件）                  |
