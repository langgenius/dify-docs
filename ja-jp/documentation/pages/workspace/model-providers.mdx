---
title: "モデルプロバイダー"
description: "Configure AI model access for your workspace—the foundation that powers all your applications"
icon: "brain-arrow-curved-right"
---

<Note> ⚠️ このドキュメントはAIによって自動翻訳されています。不正確な部分がある場合は、[英語版](/en/documentation/pages/workspace/model-providers)を参照してください。</Note>


モデルプロバイダーは、ワークスペースにAIモデルへのアクセスを提供します。構築するすべてのアプリケーションには動作するためのモデルが必要であり、ワークスペースレベルでプロバイダーを設定することで、すべてのチームメンバーがすべてのプロジェクトでモデルを使用できます。

## システムプロバイダー vs カスタムプロバイダー

**システムプロバイダー**はDifyによって管理されます。セットアップなしでモデルに即座にアクセスでき、Difyサブスクリプションを通じて請求され、新しいモデルが利用可能になると自動的に更新されます。迅速に開始するのに最適です。

**カスタムプロバイダー**は、OpenAI、Anthropic、Googleなどのモデルプロバイダーに直接アクセスするために独自のAPIキーを使用します。完全な制御、直接請求、多くの場合より高いレート制限を得られます。本番アプリケーションに最適です。

両方を同時に使用できます—プロトタイピングにはシステムプロバイダー、本番にはカスタムプロバイダーを使用できます。

## カスタムプロバイダーの設定

ワークスペースの管理者とオーナーのみがモデルプロバイダーを設定できます。プロセスはプロバイダー間で一貫しています：

<Steps>
  <Step title="設定 → モデルプロバイダーに移動">
    ワークスペース設定でモデルプロバイダー設定にアクセスします。
  </Step>
  
  <Step title="プロバイダーを選択">
    OpenAI、Anthropic、Google、Cohere、またはその他のサポートされているプロバイダーから選択します。
  </Step>
  
  <Step title="認証情報を追加">
    APIキーとプロバイダーが必要とするその他の設定を入力します。
  </Step>
  
  <Step title="テストして保存">
    Difyはプロバイダーをワークスペースで利用可能にする前に認証情報を検証します。
  </Step>
</Steps>

## サポートされているプロバイダー

**大規模言語モデル:**
- OpenAI (GPT-4, GPT-3.5-turbo)
- Anthropic (Claude)  
- Google (Gemini)
- Cohere
- Ollama経由のローカルモデル推論

**テキスト埋め込みモデル:**
- OpenAI Embeddings
- Cohere Embeddings
- Azure OpenAI
- ローカル埋め込みモデル

**専用モデル:**
- 画像生成 (DALL-E, Stable Diffusion)
- 音声 (Whisper, ElevenLabs)
- モデレーションAPI

## プロバイダー設定例

<Tabs>
  <Tab title="OpenAI">
    **必須:** OpenAI PlatformのAPIキー
    
    **オプション:** Azure OpenAIまたはプロキシ用のカスタムベースURL、組織スコープ使用のための組織ID
    
    **利用可能なモデル:** GPT-4, GPT, テキスト埋め込み
  </Tab>
  
  <Tab title="Anthropic">
    **必須:** Anthropic ConsoleのAPIキー
    
    **利用可能なモデル:** Claude 3 (Opus, Sonnet, Haiku), Claude 2.1, Claude Instant
  </Tab>
  
  <Tab title="ローカル (Ollama)">
    **必須:** OllamaサーバーURL (通常は http://localhost:11434)
    
    **セットアップ:** Ollamaをインストール、モデルをプル (`ollama pull llama2`)、Dify接続を設定
    
    **メリット:** 完全なデータプライバシー、外部API費用なし、カスタムモデルファインチューニング
  </Tab>
</Tabs>

## アクセスと請求

システムプロバイダーはDifyサブスクリプションを通じて請求され、プランに基づく使用制限があります。カスタムプロバイダーはプロバイダー（OpenAI、Anthropicなど）を通じて直接請求され、多くの場合より高いレート制限を提供します。

チームアクセスはワークスペース権限に従います：
- **オーナー/管理者**はプロバイダーを設定、修正、削除できます
- **エディター/メンバー**は利用可能なプロバイダーを表示し、アプリケーションで使用できます

<Warning>
APIキーは安全に保存されますが、ワークスペース全体のモデルアクセスを許可します。請求責任を負うべき信頼できるチームメンバーにのみ管理者権限を与えてください。
</Warning>

## トラブルシューティング

**認証失敗:** APIキーの正確性を確認し、有効期限をチェックし、十分なクレジットがあることを確認し、キーの権限を確認してください。

**モデルが利用できない:** プロバイダー設定にモデルが含まれていることを確認し、APIキーのティアアクセスを確認し、プロバイダー設定を更新してください。

**レート制限:** プロバイダーアカウントをアップグレードし、リクエストキューイングを実装し、より高い制限のためにカスタムプロバイダーを検討してください。

---

[Edit this page](https://github.com/langgenius/dify-docs/edit/main/en/guides/workspace/model-providers.mdx) | [Report an issue](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)

{/*
Contributing Section
DO NOT edit this section!
It will be automatically generated by the script.
*/}

---

[このページを編集する](https://github.com/langgenius/dify-docs/edit/main/ja-jp/documentation/pages/workspace/model-providers.mdx) | [問題を報告する](https://github.com/langgenius/dify-docs/issues/new?template=docs.yml)

