---
title: "30分钟快速入门"
description: "通过示例应用深入了解 Dify"
icon: "forward"
---

<Note> ⚠️ 本文档由 AI 自动翻译。如有任何不准确之处，请参考[英文原版](/en/use-dify/getting-started/quick-start)。</Note>

这个分步教程将带你从零开始创建一个多平台内容生成器。

除了基本的 LLM 集成，你还将发现如何使用强大的 Dify 节点来更快、更轻松地编排复杂的 AI 应用程序。

在本教程结束时，你将拥有一个工作流，它可以接受你提供的任何内容（文本、文档或图像），添加你偏好的语音和语调，并生成针对你选择语言的精美的、特定平台的社交媒体帖子。

完整的工作流如下所示。在构建过程中，可以随时参考它以保持正轨，并了解所有节点如何协同工作。

<img
  src="/images/deeper_dive_workflow_overview.png"
  alt="快速入门工作流概览"
  title="快速入门工作流概览"
  className="mx-auto"
/>

## 步骤 1：创建新工作流

1. 前往 **工作室**，然后选择 **从空白创建** \> **工作流**。
2. 将工作流命名为 `多平台内容生成器`，然后点击 **创建**。你将自动进入工作流画布开始构建。

## 步骤 2：添加和配置工作流节点

<Note>
  保持未提及的设置为默认值。
</Note>

<Tip>
  为节点和变量提供清晰、描述性的名称，使它们在工作流中更容易识别和引用。
</Tip>

### 1. 用户输入节点：收集终端用户的输入

<Info>
  首先，我们需要定义从用户那里收集什么信息，例如草稿文本、目标平台、期望的语调以及任何参考材料。

  用户输入节点是我们可以轻松设置这些的地方。我们在这里添加的每个输入字段都会成为所有下游节点可以引用和使用的变量。
</Info>

<img
  src="/images/deeper_dive_start.png"
  alt="用户输入节点"
  title="用户输入节点"
  className="mx-auto"
  style={{ width:"71%" }}
/>

点击用户输入节点，打开其配置面板，然后添加以下输入字段。

<Accordion title="参考材料 - 文本">
  - 字段类型：`段落`
  - 变量名：`draft`
  - 标签名：`草稿`
  - 最大长度：`2048`
  - 必填：`否`
</Accordion>

<Accordion title="参考材料 - 文件">
  - 字段类型：`文件列表`
  - 变量名：`user_file`
  - 标签名：`上传文件 (≤ 10)`
  - 支持文件类型：`文档`、`图片`
  - 上传文件类型：`两者`
  - 最大上传数量：`10`
  - 必填：`否`
</Accordion>

<Accordion title="语音和语调">
  - 字段类型：`段落`
  - 变量名：`voice_and_tone`
  - 标签名：`语音与语调`
  - 最大长度：`2048`
  - 必填：`否`
</Accordion>

<Accordion title="目标平台">
  - 字段类型：`短文本`
  - 变量名：`platform`
  - 标签名：`目标平台 (≤ 10)`
  - 最大长度：`256`
  - 必填：`是`
</Accordion>

<Accordion title="语言要求">
  - 字段类型：`选择`
  - 变量名：`language`
  - 标签名：`语言`
  - 选项：
    - `English`
    - `日本語`
    - `简体中文`
  - 默认值：`English`
  - 必填：`是`
</Accordion>

### 2. 参数提取器节点：识别目标平台

<Info>
  由于我们的平台字段接受自由格式的文本输入，用户可能会以各种方式输入：`x 和 linkedIn`、`在 Twitter 和 LinkedIn 上发布`，甚至 `Twitter + LinkedIn please`。然而，我们需要一个干净、结构化的列表，如 `["Twitter", "LinkedIn"]`，下游节点可以可靠地使用。

  这正是参数提取器节点的完美工作。它使用 LLM 来分析用户的自然语言，识别所有这些变化，并输出标准化的数组。
</Info>

<img
  src="/images/deeper_dive_paramater_extractor.png"
  alt="参数提取器"
  title="参数提取器"
  className="mx-auto"
  style={{ width:"73%" }}
/>

在用户输入节点之后，添加一个参数提取器节点并配置它：

1. 选择一个模型。
2. 将 `User Input/platform` 设置为输入变量。
3. 添加一个提取参数：
   1. 名称：`platform`
   2. 类型：`Array[String]`
   3. 描述：`识别并提取用户想要创建定制内容的平台。`
   4. 必填：`是`
4. 在指令字段中，粘贴以下内容来引导 LLM 进行参数提取：

   ```markdown 指令
   # 任务描述
   解析输入中的平台名称并输出为 JSON 数组。

   ## 处理规则
   - 支持多种分隔符：逗号、分号、空格、换行、"and"、"&"、"|" 等。
   - 标准化常见平台名称变体（twitter/X→Twitter，insta→Instagram 等）。
   - 删除重复和无效条目
   - 保留未知但合理的平台名称

   ## 输出要求
   - 成功：["Platform1", "Platform2"]
   - 未找到平台：[未识别到平台。请输入有效的平台名称。]

   ## 示例
   - 输入："twitter, linkedin" → ["Twitter", "LinkedIn"]
   - 输入："x and insta" → ["Twitter", "Instagram"]
   - 输入："invalid content" → [未识别到平台。请输入有效的平台名称。]
   ```

   <Check>
     注意，我们已指示 LLM 为无效输入输出特定的错误消息，这将在下一步中作为我们工作流的结束触发器。
   </Check>

### 3. IF/ELSE 节点：验证平台提取结果

<Info>
  如果用户输入了无效的平台名称，比如 `ohhhhhh` 或 `BookFace` 怎么办？我们不想浪费时间和令牌生成无用的内容。

  在这种情况下，我们可以使用 IF/ELSE 节点创建一个分支，提前停止工作流。我们将设置一个条件来检查参数提取器节点的错误消息；如果检测到该消息，工作流将直接路由到输出节点并结束。
</Info>

<img
  src="/images/deeper_dive_if.png"
  alt="If 条件"
  className="mx-auto"
  style={{ width:"80%" }}
  title="If 条件"
/>

1. 在参数提取器节点之后，添加一个 IF/ELSE 节点。
2. 在 IF/ELSE 节点的面板上，定义 IF 条件：

   **IF** `Parameter Extractor/platform` `包含` `未识别到平台。请输入有效的平台名称。`
3. 在 IF/ELSE 节点之后，向 IF 分支添加一个输出节点。
4. 在输出节点的面板上，将 `Parameter Extractor/platform` 设置为输出变量。

### 4. 列表操作器节点：按类型分离上传的文件

<Info>
  我们的用户可以上传图像和文档作为参考材料，但这两种类型需要不同的处理：图像可以由启用视觉的模型直接解释，而文档必须首先转换为文本，LLM 才能理解其内容。

  为了管理这一点，我们将使用两个列表操作器节点来过滤和将上传的文件分成单独的分支——一个用于图像，一个用于文档。
</Info>

<img
  src="/images/deeper_dive_list_operator.png"
  alt="列表操作器"
  className="mx-auto"
  style={{ width:"70%" }}
  title="列表操作器"
/>

1. 在 IF/ELSE 节点之后，向 ELSE 分支添加两个列表操作器节点。
2. 将一个节点重命名为 `图像`，另一个重命名为 `文档`。
3. 配置图像节点：
   1. 将 `User Input/user_file` 设置为输入变量。
   2. 启用过滤条件：`{x}type` `在` `Image`
4. 配置文档节点：
   1. 将 `User Input/user_file` 设置为输入变量。
   2. 启用过滤条件：`{x}type` `在` `Doc`。

### 5. 文档提取器节点：从文档中提取文本

<Info>
  LLM 不能直接读取像 PDF 或 DOCX 这样的上传文件。要使用这些文档中的信息，我们必须首先将它们转换为 LLM 可以处理的纯文本。

  这正是文档提取器节点所做的。它将文档文件作为输入，并为下一步输出干净、可用的文本。
</Info>

1. 在文档节点之后，添加一个文档提取器节点。
2. 在文档提取器节点的面板上，将 `Document/result` 设置为输入变量。

### 6. LLM 节点：整合所有参考材料

<Info>
  当用户同时提供多种参考类型——草稿文本、文档和图像时，我们需要将它们整合成一个连贯的摘要。

  LLM 节点将通过分析所有分散的片段来处理此任务，创建一个指导后续内容生成的综合上下文。
</Info>

<img
  src="/images/deeper_dive_info_integrate.png"
  alt="整合信息"
  className="mx-auto"
  style={{ width:"78%" }}
  title="整合信息"
/>

1. 在文档提取器节点之后，添加一个 LLM 节点。
2. 将图像节点也连接到这个 LLM 节点。
3. 点击 LLM 节点进行配置：
   1. 将其重命名为 `整合信息`。
   2. 选择一个支持视觉的模型（由眼睛图标表示）。
   3. 启用 **视觉** 并将 `Image/result` 设置为视觉变量。
   4. 在系统提示字段中，粘贴以下内容：

      <Warning>
        在提示中，要在 _提供的材料_ 中引用 `Doc Extractor/text` 和 `User Input/draft` 变量，请键入 `{` 或 `/` 并从列表中选择。

        <img
          src="/images/deeper_dive_reference_variable.png"
          alt="引用变量"
          title="引用变量"
          className="mx-auto"
          style={{ width:"58%" }}
        />
      </Warning>
      ```markdown 系统 {2,3}
      # 提供的材料
      Doc Extractor/text
      User Input/draft

      # 角色与任务
      你是一名内容策略师。分析提供的材料并为多平台社交媒体优化创建综合内容基础。

      # 分析原则
      - 仅使用提供的信息——不做外部假设
      - 专注于提取、综合和战略解释
      - 识别引人注目和可操作的元素
      - 准备可跨不同平台调整的见解

      # 所需分析
      提供结构化分析：

      ## 1. 核心信息
      - 中心主题、目的、目标
      - 传达的关键价值或利益

      ## 2. 基本内容元素
      - 主要主题、事实、统计数据、数据点
      - 值得注意的引言、推荐、关键陈述
      - 提到的特性、利益、特征
      - 日期、地点、背景细节

      ## 3. 战略见解
      - 使内容引人注目/独特的原因
      - 存在的情感/理性诉求
      - 可信度因素、证明点
      - 突出的竞争优势

      ## 4. 参与机会
      - 出现的讨论点、问题
      - 建议的行动号召、下一步
      - 互动/参与机会
      - 涉及的热门主题

      ## 5. 平台优化基础
      - 高影响力：快速、可分享的格式
      - 专业：以商业为重点的讨论
      - 社区：互动和分享
      - 视觉：通过强大的视觉效果增强

      ## 6. 支持细节
      - 指标、数字、可量化的结果
      - 直接引言、推荐
      - 技术细节、规格
      - 可用的背景上下文
      ```

### 7. 迭代节点：为每个平台创建定制内容

<Info>
  现在整合的参考和目标平台已准备就绪，让我们使用迭代节点为每个平台生成定制的帖子。

  该节点将遍历平台列表并为每个平台运行子工作流：首先分析特定平台的风格指南和最佳实践，然后基于所有可用信息生成优化的内容。
</Info>

<img
  src="/images/deeper_dive_integration.png"
  alt="迭代节点"
  className="mx-auto"
  style={{ width:"62%" }}
  title="迭代节点"
/>

1. 在整合信息节点之后，添加一个迭代节点。
2. 在迭代节点内部，添加一个 LLM 节点并配置它：
   1. 将其重命名为 `识别风格`。
   2. 选择一个模型。
   3. 在系统提示字段中，粘贴以下内容：

      <Warning>
        在提示中，要在 _角色与任务_ 和 _输出格式示例_ 中引用 `Current Iteration/item` 变量，请键入 `{` 或 `/` 并从列表中选择。
      </Warning>
      ````markdown 系统 {2,40}
      # 角色与任务
      你是社交媒体专家。分析平台 "Current Iteration/item" 并提供内容创建指南。

      # 所需分析
      对于给定的平台，提供：

      ## 1. 平台概况
      - 平台类型和类别
      - 目标受众特征

      ## 2. 内容指南
      - 最佳内容长度（字符/单词）
      - 推荐语调（专业/休闲/对话）
      - 格式最佳实践（换行、表情符号等）

      ## 3. 参与策略
      - 标签建议（数量和风格）
      - 行动号召最佳实践
      - 算法优化提示

      ## 4. 技术规格
      - 字符/单词限制
      - 视觉内容要求
      - 特殊格式需求

      ## 5. 平台特定注意事项
      - 独特功能或最近的变化
      - 行业特定考虑
      - 社区参与方法

      # 输出要求
      - 对于已识别的平台：提供特定指南
      - 对于未知平台：基于类似平台的建议
      - 专注于可操作、实用的建议
      - 简洁但全面

      # 输出格式示例
      ```json
      {
        "platform_name": "Current Iteration/item",
        "platform_type": "社媒/专业网络/视觉平台/微博客",
        "content_guidelines": {
          "max_length": "字符/单词限制",
          "optimal_length": "推荐范围",
          "tone": "专业/休闲/对话/权威",
          "hashtag_strategy": "数量和位置指南",
          "formatting": "换行、表情符号、提及指南",
          "engagement_focus": "评论/分享/点赞/转发",
          "call_to_action": "适当的 CTA 风格"
        },
        "special_considerations": "任何独特的平台要求或最近的变化",
        "confidence_level": "基于平台识别的高/中/低"
      }
      ````
3. 在识别风格节点之后，添加另一个 LLM 节点并配置它：
   1. 将其重命名为 `创建内容`。
   2. 选择一个模型。
   3. 在系统提示字段中，粘贴以下内容：

      <Warning>
        在提示中，要引用以下变量，请键入 `{` 或 `/` 并从列表中选择。
        - _平台指南_ 中的 `Identify Style/text`
        - _来源信息_ 中的 `Integrate Info/text`
        - _语音与语调（可选）_ 中的 `User Input/voice_and_tone`
        - _语言要求_ 中的 `User Input/language`
      </Warning>
      ```markdown 系统 {6,9,12,15}
      # 角色与任务
      你是专业的社交媒体内容创作者。生成符合平台指南、整合来源信息并遵循指定语音/语调和语言要求的发布就绪内容。

      # 输入材料
      ## 1. 平台指南
      Identify Style/text

      ## 2. 来源信息
      Integrate Info/text

      ## 3. 语音与语调（可选）
      Start/voice_and_tone

      ## 4. 语言要求
      - 专门使用以下语言生成所有内容：User Input/language
      - 不得混用语言
      - 将平台术语调整为指定语言

      # 内容要求
      - 严格遵循平台指南（格式、长度、语调、标签）
      - 有效整合来源信息（关键信息、数据、价值主张）
      - 一致地应用语音与语调（如果提供）
      - 针对平台特定的参与进行优化
      - 确保指定语言的文化适当性

      # 输出格式
      - 仅生成最终的社交媒体帖子内容。没有解释或元评论。内容必须立即可复制粘贴。
      - 最大标题级别：##（H2）- 永远不要使用 #（H1）
      - 没有水平分隔符：避免 ---

      # 质量检查清单
      ✅ 遵循平台指南
      ✅ 整合来源信息
      ✅ 语音/语调一致（提供时）
      ✅ 保持语言一致性
      ✅ 优化参与度
      ✅ 发布就绪
      ```
   4. 启用结构化输出。

      <img
        src="/images/deeper_dive_structured_output.png"
        alt="结构化输出"
        title="结构化输出"
        className="mx-auto"
        style={{ width:"64%" }}
      />
      1. 在 **输出变量** 旁边，将 **结构化** 切换为开启。structured_output 变量将出现在下方。
      2. 在 **structured_output** 旁边，点击 **配置**。
      3. 在弹出的架构编辑器中，点击右上角的 **从 JSON 导入**，并粘贴以下内容：

         ```json
         {
           "platform_name": "string",
           "post_content": "string"
         }
         ```
4. 点击迭代节点进行配置：
   1. 将 `Parameter Extractor/platform` 设置为输入变量。
   2. 将 `Create Content/structured_output` 设置为输出变量。
   3. 启用 **并行模式** 并将最大并行度设置为 `10`。

      <Check>
        这就是为什么我们在用户输入节点的目标平台字段的标签名称中包含了 `(≤10)`。
      </Check>

### 8. 模板节点：格式化最终输出

<Info>
  迭代节点为每个平台生成一个帖子，但其输出是原始数据数组（例如，`[{"platform_name": "Twitter", "post_content": "..."}]`），不太可读。我们需要以更清晰的格式呈现结果。

  这就是模板节点的用武之地——它允许我们使用 [Jinja2](https://jinja.palletsprojects.com/en/stable/) 模板将这些原始数据格式化为组织良好的文本，确保最终输出用户友好且易于理解。
</Info>

<img
  src="/images/deeper_dive_template.png"
  alt="模板节点"
  title="模板节点"
  style={{ width:"49%" }}
  className="mx-auto"
/>

1. 在迭代节点之后，添加一个模板节点。
2. 在模板节点的面板上，将 `Iteration/output` 设置为输入变量。
3. 粘贴以下 Jinja2 代码（**记得删除注释**）。

   ```
   {% for item in output %}        # 遍历输入数组中的每个平台-内容对
   # 📱 {{ item.platform_name }}   # 显示平台名称作为带有手机表情符号的 H1 标题
   {{ item.post_content }}        # 显示为此平台生成的内容
                                  # 在平台之间添加空行以提高可读性
   {% endfor %}                   # 结束循环
   ```

   <Tip>
     虽然 LLM 也可以处理输出格式化，但它们的输出可能不一致且不可预测。对于不需要推理的基于规则的格式化，模板节点以更稳定可靠的方式完成任务，且成本为零令牌。

     LLM 非常强大，但知道何时使用正确的工具是构建更可靠和经济高效的 AI 应用程序的关键。
   </Tip>

### 9. 输出节点：将结果返回给用户

1. 在模板节点之后，添加一个输出节点。
2. 在输出节点的面板上，将 `Template/output` 设置为输出变量。

## 步骤 3：测试

你的工作流现在已完成！让我们测试一下。

1. 确保你的检查列表已清除。

   <img
     src="/images/deeper_dive_checklist_clear.png"
     alt="检查检查列表"
     className="mx-auto"
     style={{ width:"77%" }}
     title="检查检查列表"
   />
2. 对照开头提供的参考图检查你的工作流，确保所有节点和连接都匹配。
3. 点击右上角的 **运行**，填写输入字段，然后点击 **开始运行**。

   要使用缓存的输入运行单个节点，请点击其配置面板顶部的 **运行此步骤** 图标。

   <Tip>
     要测试节点对来自先前节点的不同输入的反应，你不需要重新运行整个工作流。只需点击画布底部的 **查看缓存变量**，从列表中找到要更改的变量，然后编辑其值。
   </Tip>
   如果遇到任何错误，请检查相应节点的 **最后运行** 日志以确定问题的确切原因。

## 步骤 4：发布和共享

一旦工作流按预期运行并且你对结果感到满意，点击 **发布** \> **发布更新** 使其生效并可共享。

<Warning>
  如果你稍后进行任何更改，请始终记住再次发布，以便更新生效。
</Warning>

<Tip>
  发布后，你可以在实时环境中运行快速的端到端测试，以确认一切工作与 **工作室** 中相同。
</Tip>
